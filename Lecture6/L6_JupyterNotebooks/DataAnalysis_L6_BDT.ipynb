{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Examples of using Boosted Decision Trees with scikit-learn \n",
    "\n",
    "Using BDTs in sklearn:  \n",
    "1. BDT regressor\n",
    "2. BDT classifier\n",
    "\n",
    "Show interface on how to setup, train and apply the BDT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression with AdaBoost\n",
    "\n",
    "\n",
    "A decision tree is boosted using the AdaBoost algorithm on a 1D\n",
    "sinusoidal dataset with a small amount of Gaussian noise.\n",
    "A 299 boosts (300 decision trees) regressor is compared with a single decision tree\n",
    "regressor. The boosted regressor can fit more\n",
    "detail than the single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Noel Dawe <noel.dawe@gmail.com>\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# First: import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create a simple dataset of x and y values that we want to describe\n",
    "\n",
    "# Seed the random number generator \"rng\" to make result repeatable\n",
    "rng = np.random.RandomState(1)\n",
    "# create 100 x-axis values from 0 to 6 \n",
    "X = np.linspace(0, 6, 100)[:, np.newaxis]\n",
    "print(\"Type of X is \",type(X))\n",
    "print(\"X = \",X)\n",
    "\n",
    "# For each x value create a y value that is determined based on the \n",
    "# sum of two sine functions and Gaussian noise from the random number generator\n",
    "y = np.sin(X).ravel() + np.sin(6 * X).ravel() + rng.normal(0, 0.1, X.shape[0])\n",
    "print(\"Type of y is \",type(y))\n",
    "print(\"y = \",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot this\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.xlabel(\"x value (data input)\")\n",
    "plt.ylabel(\"y value (target)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up two regression models\n",
    "#regr_1 is a single tree with a maximum depth of 4\n",
    "regr_1 = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "#regr_2 is a boosted decision tree of up to 300 individual trees with a maximum depth of 4\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=300, random_state=rng)\n",
    "# train the two models\n",
    "# this is all!\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "# Use the models to predict values\n",
    "# predict() takes all the X values in the array and predicts a y value based on the trained decision tree\n",
    "\n",
    "y_1 = regr_1.predict(X)\n",
    "y_2 = regr_2.predict(X)\n",
    "\n",
    "# Plot the results of the first regressor\n",
    "plt.figure()\n",
    "plt.scatter(X, y, c=\"k\", label=\"training sample\")\n",
    "plt.plot(X, y_1, c=\"g\", label=\"n_estimators=1\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"x value (data input)\")\n",
    "plt.ylabel(\"y value (target)\")\n",
    "plt.title(\"Boosted Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare with the Adaboost BDT result:\n",
    "plt.figure()\n",
    "plt.scatter(X, y, c=\"k\", label=\"training sample\")\n",
    "plt.plot(X, y_1, c=\"g\", label=\"n_estimators=1\", linewidth=2)\n",
    "plt.plot(X, y_2, c=\"r\", label=\"n_estimators=300\", linewidth=2)\n",
    "plt.xlabel(\"x value (data input)\")\n",
    "plt.ylabel(\"y value (target)\")\n",
    "plt.title(\"Boosted Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BDT gives a better description that the simple depth=4 single tree\n",
    "# what is we increase the depth of the single tree to 300? \n",
    "\n",
    "regr_3 = DecisionTreeRegressor(max_depth=300)\n",
    "\n",
    "# train the tree\n",
    "\n",
    "regr_3.fit(X, y)\n",
    "\n",
    "# Use the models to predict values\n",
    "y_3 = regr_3.predict(X)\n",
    "\n",
    "\n",
    "# Plot the results of the first regressor\n",
    "plt.figure()\n",
    "plt.scatter(X, y, c=\"k\", label=\"training sample\")\n",
    "plt.plot(X, y_3, c=\"b\", label=\"n_estimators=1\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"x value (data input)\")\n",
    "plt.ylabel(\"y value (target)\")\n",
    "plt.title(\"Decision Tree Regression for max depth = 400\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does this regressor do when we give it some data that it has not seen before?\n",
    "\n",
    "# Shift X values by 0.1 compared to training sample\n",
    "X2 = np.linspace(0.1, 6.1, 100)[:, np.newaxis]\n",
    "\n",
    "# New target values with different random noise\n",
    "y2 = np.sin(X2).ravel() + np.sin(6 * X2).ravel() + rng.normal(0, 0.1, X2.shape[0])\n",
    "plt.figure()\n",
    "\n",
    "y_3 = regr_3.predict(X2)\n",
    "\n",
    "\n",
    "# Plot the results of the first regressor\n",
    "plt.figure()\n",
    "plt.scatter(X2, y2, c=\"k\", label=\"training sample 2\")\n",
    "plt.plot(X2, y_3, c=\"b\", label=\"n_estimators=1\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"x value (data input)\")\n",
    "plt.ylabel(\"y value (target)\")\n",
    "plt.title(\"Decision Tree Regression for max depth = 400\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a BDT classifier\n",
    "\n",
    "__First, load the libraries we need__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load the \"iris\" dataset that comes with Scikit learn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn comes with some example data sets\n",
    "from sklearn import datasets\n",
    "\n",
    "# load the \"iris\" data set\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(f\"Iris data set contains {len(iris.data)} objects (different flowers)\")\n",
    "print(\"Each object has 4 features:\",iris.feature_names)\n",
    "print(\"and belongs in one of three classes:\",iris.target_names)\n",
    "print(\"Feature data: \\n\", iris.data)\n",
    "print(\"Object classes:\\n\", (iris.target))\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(iris.data[:, 0], iris.data[:, 1], c=iris.target)\n",
    "ax.set(xlabel=iris.feature_names[0], ylabel=iris.feature_names[1])\n",
    "ax.legend(scatter.legend_elements()[0], iris.target_names, loc=\"lower right\", title=\"Classes\")\n",
    "ax.set_title(\"3 types of flowers; features 0, 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(iris.data[:, 2], iris.data[:, 3], c=iris.target)\n",
    "ax.set(xlabel=iris.feature_names[2], ylabel=iris.feature_names[3])\n",
    "ax.legend(scatter.legend_elements()[0], iris.target_names, loc=\"lower right\", title=\"Classes\")\n",
    "ax.set_title(\"3 types of flowers; features 2, 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=1,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is interesting to see which class of flowers the BDT gets right and wrong\n",
    "# we can look at the \"confusion matrix\"\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
