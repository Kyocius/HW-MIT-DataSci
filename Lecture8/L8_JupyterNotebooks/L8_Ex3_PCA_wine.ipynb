{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7861a71",
   "metadata": {},
   "source": [
    "# Principal component analysis with scikit-learn\n",
    "\n",
    "Use a principal component analysis on a dataset with 13 features\n",
    "\n",
    "We'll use the \"wine\" dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e929fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import standard stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "#Import scikit-learn MLP classifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "#Import datasets so we can access the \"digits\" dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "#import the wine dataset into a pandas dataframe\n",
    "wine_data = datasets.load_wine(as_frame=True)\n",
    "df = wine_data.data\n",
    "print(df.info())\n",
    "print(\"Shape is \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6a116",
   "metadata": {},
   "source": [
    "\"wine\" data are the results of a chemical analysis of wines grown in the same region in Italy. The analysis determined the quantities of __13 constituents__ found in each of __three__ types of wines. There are __178__ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0cc4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    x = df[col]\n",
    "    x.plot.hist()\n",
    "    plt.xlabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65560aa8",
   "metadata": {},
   "source": [
    "All the features have a very different range of values. To make the task of the PCA easier, we can preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd30dee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# standard scaler transforms the features such that the mean is 0 and the variance is 1\n",
    "X = std_scaler.fit_transform(df)\n",
    "\n",
    "i=0\n",
    "for col in df.columns:\n",
    "    plt.hist(X[:,i])\n",
    "    print(f\"mean, variance: {np.mean(X[:,i]):.3} , {np.var(X[:,i]):.3}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the PCA method from sklearn\n",
    "# this will do all the work for us\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# we can set the number of PCA components we want to reduce the data set to\n",
    "pca = PCA(n_components=3)\n",
    "# there are two steps\n",
    "# first, we find the principal components\n",
    "pca.fit(X)\n",
    "\n",
    "# we can then also transform the input data into \n",
    "# a representation by the three components only\n",
    "Xpca = pca.transform(X)\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(Xpca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2500a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three PCA components represent the directions of maximum variance\n",
    "# in the 13-dimensional feature space\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well do the PCA components explain the variation in the original data\n",
    "print(f\"PCA explains {sum(pca.explained_variance_ratio_):.3} of the data variance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d18810",
   "metadata": {},
   "source": [
    "How does the explained variance change with the number of components we allow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an array of numbers from 1 to 14\n",
    "nums = np.arange(14)\n",
    "print(nums)\n",
    "\n",
    "var_ratio = []\n",
    "for num in nums:\n",
    "  pca = PCA(n_components=num)\n",
    "\n",
    "# we don't need to do the transform step every time\n",
    "  pca.fit(X)\n",
    "\n",
    "# record the total variance explained for each number of components\n",
    "  var_ratio.append(np.sum(pca.explained_variance_ratio_))\n",
    "    \n",
    "#plot explained variance vs number of components\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.grid()\n",
    "plt.plot(nums,var_ratio,marker='o')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.title('n_components vs. Explained Variance Ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf725cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
